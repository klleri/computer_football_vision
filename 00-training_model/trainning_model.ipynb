{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "898bb7d2",
   "metadata": {},
   "source": [
    "# Train Football Player Detector\n",
    "\n",
    "This jupyter Notebook guides you through training object detection model to detect football players.  It's based on the excellent tutorial [How to Train YOLOv8 Object Detection on a Custom Dataset](<https://github.com/roboflow/notebooks/blob/main/notebooks/train-yolov8-object-detection-on-custom-dataset.ipynb>). Also we'll be using a football player dataset hosted on Roboflow.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "*   **Roboflow Account:** You'll need a free Roboflow account.  Sign up at [https://roboflow.com/](https://roboflow.com/).\n",
    "*  **Dataset**: We'll use a pre-existing football player dataset on Roboflow.\n",
    "*   **Roboflow API Key:** This key allows your notebook to interact with your Roboflow account and download the dataset.\n",
    "\n",
    "## Step 1: Configure Your Roboflow API Key\n",
    "\n",
    "To access your dataset from Roboflow, you'll need your private API key.\n",
    "\n",
    "1.  **Get Your API Key:**\n",
    "    *   Go to your Roboflow dashboard: [https://app.roboflow.com/](https://app.roboflow.com/)\n",
    "    *   Click on your profile icon (usually in the top right corner) and select \"Settings\" or \"Roboflow API\".\n",
    "    *   Navigate to the \"API\" section.\n",
    "    *   Click the \"Show\" button next to your Private API Key and then **Copy** the key to your clipboard.\n",
    "\n",
    "2.  **Securely Store Your API Key (Important!):**\n",
    "    *   **In Google Colab (Recommended):**\n",
    "        *   On the left sidebar, click the \"Secrets\" icon (it looks like a key ðŸ”‘).\n",
    "        *   Click \"+ Secret\".\n",
    "        *   In the \"Name\" field, enter `ROBOFLOW_API_KEY` (all caps, exactly like this).\n",
    "        *   In the \"Value\" field, paste your Roboflow API key.\n",
    "        *   Click \"Add Secret.\"\n",
    "\n",
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29d5b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6da8cad",
   "metadata": {},
   "source": [
    "## Step 3: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9812e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from roboflow import Roboflow\n",
    "from ultralytics import YOLO \n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc65f35",
   "metadata": {},
   "source": [
    "## Step 4: Download the Dataset from Roboflow \n",
    "\n",
    "*  **Dataset**: We'll use the football player detection dataset hosted on Roboflow: [Football Players Detection Dataset](https://universe.roboflow.com/roboflow-jvuqo/football-players-detection-3zvbc).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb834244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"YOUR_KEY_HERE\")\n",
    "project = rf.workspace(\"roboflow-jvuqo\").project(\"football-players-detection-3zvbc\")\n",
    "version = project.version(12)\n",
    "dataset = version.download(\"yolov11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f79212",
   "metadata": {},
   "source": [
    "## Step 5: Train the Model\n",
    "\n",
    "Now that we have our dataset downloaded, we can train our YOLO model. There are two main ways to do this: locally on your own computer, or using Google Colab (which provides free cloud-based GPU resources).\n",
    "\n",
    "**Option 1: Training Locally (on Your Computer)**\n",
    "\n",
    "This option requires you to have a suitable Python environment set up on your machine, with all the necessary dependencies installed.  If you have a powerful GPU, local training can be very fast.\n",
    "\n",
    "### ---  Training Locally  ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89acbd21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11n.pt\")\n",
    "results = model.train(data=\"/data.yaml\", epochs=100, imgsz=640, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa4d590",
   "metadata": {},
   "source": [
    "**Option 2: Training using Google Colab (Recommended)** \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e62b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train model=yolo11n.pt data={dataset.location}/data.yaml epochs=100 imgsz=640"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3aa2cb",
   "metadata": {},
   "source": [
    "\n",
    "#### task\n",
    "\n",
    "The `task` parameter defines the specific computer vision task you want to perform.\n",
    "\n",
    "*   **Available Options:**\n",
    "    *   `detect`: **Object Detection.**  The model identifies objects within images, drawing bounding boxes around them along with class labels and confidence scores.\n",
    "    *   `segment`: **Instance Segmentation.** Similar to object detection, but the model creates pixel-perfect masks outlining each object, providing more precise localization.\n",
    "    *   `classify`: **Image Classification.** The model predicts a single class label for the *entire* image (e.g., \"cat,\" \"dog,\" \"car\"). It doesn't locate objects *within* the image.\n",
    "    *   `pose`: **Pose Estimation.** The model identifies keypoints on objects (typically humans, e.g., joints like elbows, knees). Useful for analyzing posture and movement.\n",
    "\n",
    "#### mode\n",
    "\n",
    "The `mode` parameter determines what action you want to perform with the model.\n",
    "\n",
    "*   **Available Options:**\n",
    "    *   `train`: **Train a model.** Train a new model or fine-tune an existing one.\n",
    "    *   `val`: **Validate a model.** Evaluate a trained model's performance on a validation dataset to assess generalization.\n",
    "    *   `predict`: **Make predictions.** Use a trained model for inference (detection, segmentation, etc.) on new images/videos.\n",
    "    *   `export`: **Export a model.** Convert a trained model to formats like ONNX, TensorFlow Lite, or CoreML for deployment.\n",
    "    *   `track`: **Object Tracking.** Use a trained detection model with a tracker to follow objects in a video.\n",
    "\n",
    "#### model\n",
    "\n",
    "The `model` parameter specifies the architecture and initial weights.\n",
    "\n",
    "*   **Available Options:**\n",
    "     *   `yolov11n.pt` (Nano - smallest, fastest)\n",
    "     *   `yolov11s.pt` (Small)\n",
    "     *   `yolov11m.pt` (Medium)\n",
    "     *   `yolov11l.pt` (Large)\n",
    "     *   `yolov11x.pt` (Extra Large - largest, most accurate, slowest)\n",
    "       \n",
    "    *   **Custom Models:** Specify the path to a custom `.pt` file with your own trained weights.\n",
    "    *   **YAML Configuration Files:** (Advanced) Provide a `.yaml` file defining the model architecture.\n",
    "\n",
    "#### data\n",
    "\n",
    "The `data` parameter points to a YAML file containing information about our dataset.\n",
    "\n",
    "#### epochs\n",
    "\n",
    "The `epochs` parameter controls the number of training iterations. One epoch means the model has seen every image in your training dataset once.\n",
    "\n",
    "*   **Considerations:**\n",
    "    *   More epochs *can* improve performance, but too many can lead to *overfitting* (poor generalization).\n",
    "    *   The optimal number depends on your dataset, model, and other factors.\n",
    "\n",
    "#### imgsz\n",
    "\n",
    "The `imgsz` parameter specifies the input image size (in pixels) for training and inference. \n",
    "\n",
    "*   **Considerations:**\n",
    "    *   Larger sizes (e.g., `imgsz=1280`) *can* improve accuracy, especially for small objects, but require more resources.\n",
    "    *   Smaller sizes (e.g., `imgsz=320`) are faster but may reduce accuracy.\n",
    "    *   `640` is a common default.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c4864",
   "metadata": {},
   "source": [
    "**The information in this section is based on the official Ultralytics YOLOv8 documentation:** [Resuming Interrupted Trainings](https://docs.ultralytics.com/modes/train/#resuming-interrupted-trainings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
